{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhlaiwoWXj4TmcNBILNMVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kai-nat/CS-370-Artificial-Intelligence/blob/main/ADS2_7PAM2001_0901_Assignment_1_Deep_Learning_with_Keras_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JPuMiKF7Q8bN"
      },
      "outputs": [],
      "source": [
        "# Module imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a class called latent_sampling, which subclasses layers.Layer.\n",
        "### The class should perform the reparameterisation trick in its .call()\n",
        "### method.\n",
        "### Reparameterization Trick: z = mean + epsilon * exp(ln(variance) * 0.5)\n",
        "### epsilon = N(0,1), a unit normal with same dims as mean and variance\n",
        "\n",
        "# Include the follow two lines in your .call method:\n",
        "# self.add_loss(-0.5 * tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar)))\n",
        "# self.add_metric(-0.5 * tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar)), name='kl_loss'\n",
        "\n",
        "class latent_sampling(layers.Layer):\n",
        "    def __init__(self, units=32, input_dim=32):\n",
        "        super(latent_sampling, self).__init__()\n",
        "        self.units = units\n",
        "        self.input_dim = input_dim\n",
        "        self.mean = Dense(self.units, activation='relu')\n",
        "        self.logvar = Dense(self.units, activation='relu')\n",
        "        self.epsilon = tf.random.normal(shape=(self.input_dim, self.units))\n",
        "        self.z = self.mean + tf.exp(0.5 * self.logvar) * self.epsilon\n",
        "        self.add_loss(-0.5 * tf.reduce_sum(1 + self.logvar - tf.square(self.mean) - tf.exp(self.logvar)))\n",
        "        self.add_metric(-0.5 * tf.reduce_sum(1 + self.logvar - tf.square(self.mean) - tf.exp(self.logvar)), name='kl_loss')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.z"
      ],
      "metadata": {
        "id": "BZ_WMC6u62jU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the encoder model, using the functional API and the architecture\n",
        "### detailed below. Use tf.keras.models.Model to initialise the model.\n",
        "\n",
        "# Model: \"encoder\"\n",
        "# ____________________________________________________________________________________________________\n",
        "#  Layer (type)            Output Shape           Activation  kernel_size  padding  Input\n",
        "# ====================================================================================================\n",
        "#  enc_input (InputLayer)  [(None, 128, 128, 3)]  None\n",
        "#  enc_conv_1 (Conv2D)     (None, 64, 64, 32)     ReLU        (3,3)        'same'   enc_input\n",
        "#  enc_conv_2 (Conv2D)     (None, 32, 32, 64)     ReLU        (3,3)        'same'   enc_conv_1\n",
        "#  enc_conv_3 (Conv2D)     (None, 16, 16, 64)     ReLU        (3,3)        'same'   enc_conv_2    \n",
        "#  enc_conv_4 (Conv2D)     (None, 8, 8, 64)       ReLU        (3,3)        'same'   enc_conv_3    \n",
        "#  enc_flat (Flatten)      (None, 4096)           None        None         None     enc_conv_4\n",
        "#  z_mean (Dense)          (None, 200)            None        None         None     enc_flat                        \n",
        "#  z_log_var (Dense)       (None, 200)            None        None         None     enc_flat\n",
        "#  z (latent_sampling)     (None, 200)            None        None         None     (z_mean, z_log_var)\n",
        "\n",
        "def encoder_model():\n",
        "    enc_input = layers.Input(shape=(128, 128, 3), name='enc_input')\n",
        "    enc_conv_1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='enc_conv_1')(enc_input)\n",
        "    enc_conv_2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='enc_conv_2')(enc_conv_1)\n",
        "    enc_conv_3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='enc_conv_3')(enc_conv_2)\n",
        "    enc_conv_4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='enc_conv_4')(enc_conv_3)\n",
        "    enc_flat = layers.Flatten(name='enc_flat')(enc_conv_4)\n",
        "    z_mean = layers.Dense(200, name='z_mean')(enc_flat)\n",
        "    z_log_var = layers.Dense(200, name='z_log_var')(enc_flat)\n",
        "    z = latent_sampling(200, 200)([z_mean, z_log_var])\n",
        "    return keras.Model(enc_input, z, name='encoder')"
      ],
      "metadata": {
        "id": "NCJJ9d2J68gN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the decoder model, using the functional API and the architecture\n",
        "### detailed below. Use tf.keras.models.Model to initialise the model.\n",
        "\n",
        "# Model: \"decoder\"\n",
        "# ____________________________________________________________________________________________________\n",
        "#  Layer (type)                   Output Shape           Activation  kernel_size  padding  Input\n",
        "# ====================================================================================================\n",
        "#  dec_input (InputLayer)         [(None, 200)]          None\n",
        "#  dec_dense (Dense)              (None, 4096)           ReLU        None         None     dec_input\n",
        "#  dec_reshape (Reshape)          (None, 8, 8, 64)       None        None         None     dec_dense\n",
        "#  dec_conv_1 (Conv2DTranspose)   (None, 8, 8, 64)       ReLU        (3,3)        'same'   dec_reshape\n",
        "#  dec_conv_2 (Conv2DTranspose)   (None, 16, 16, 64)     ReLU        (3,3)        'same'   dec_conv_1\n",
        "#  dec_conv_3 (Conv2DTranspose)   (None, 32, 32, 64)     ReLU        (3,3)        'same'   dec_conv_2    \n",
        "#  dec_conv_4 (Conv2DTranspose)   (None, 64, 64, 32)     ReLU        (3,3)        'same'   dec_conv_3    \n",
        "#  dec_output (Conv2DTranspose)   (None, 128, 128, 3)    ReLU        (3,3)        'same'   dec_conv_4\n",
        "\n",
        "def decoder_model():\n",
        "    dec_input = layers.Input(shape=(200,), name='dec_input')\n",
        "    dec_dense = layers.Dense(4096, activation='relu', name='dec_dense')(dec_input)\n",
        "    dec_reshape = layers.Reshape((8, 8, 64), name='dec_reshape')(dec_dense)\n",
        "    dec_conv_1 = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='dec_conv_1')(dec_reshape)\n",
        "    dec_conv_2 = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='dec_conv_2')(dec_conv_1)\n",
        "    dec_conv_3 = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='dec_conv_3')(dec_conv_2)\n",
        "    dec_conv_4 = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same', name='dec_conv_4')(dec_conv_3)\n",
        "    dec_output = layers.Conv2DTranspose(3, (3, 3), activation='relu', padding='same', name='dec_output')(dec_conv_4)\n",
        "    return keras.Model(dec_input, dec_output, name='decoder')\n"
      ],
      "metadata": {
        "id": "S3DWzgJK7BzD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the VAE model, again using tf.keras.models.Model, with the function\n",
        "### API to combine the feed the outputs of the encoder into the inputs of the\n",
        "### decoder.\n",
        "\n",
        "# Model: \"vae\"\n",
        "\n",
        "def vae_model():\n",
        "    encoder = encoder_model()\n",
        "    decoder = decoder_model()\n",
        "    vae_input = layers.Input(shape=(128, 128, 3), name='vae_input')\n",
        "    z = encoder(vae_input)\n",
        "    vae_output = decoder(z)\n",
        "    return keras.Model(vae_input, vae_output, name='vae')\n"
      ],
      "metadata": {
        "id": "Z7CV-tDV7IoM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Provided here are the loss functions for the VAE model.\n",
        "\n",
        "def recon_loss(y_true, y_pred):\n",
        "    recon = tf.reduce_sum(tf.square(y_true-y_pred), axis=(1,2,3))\n",
        "    return tf.reduce_mean(recon)"
      ],
      "metadata": {
        "id": "WNNV5nRA8FSi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is provided to load a subsample of the celeb_a dataset, and process\n",
        "# the images into the correct format for the model.\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def img_process(features):\n",
        "    \"\"\"\n",
        "    A preprocessing fuction for the test and validation datasets. This function\n",
        "    accepts the oxford_iiit_pet dataset, extracts the images and species label,\n",
        "    and resizes and rescales the images.\n",
        "    \"\"\"\n",
        "    image = tf.image.resize(features['image'], (128,128))\n",
        "    image = tf.cast(image, 'float32')/255.\n",
        "    return image, image\n",
        "\n",
        "\n",
        "train_ds, test_ds = tfds.load('celeb_a', split=['train[:10%]', 'test[:10%]'], download=True, shuffle_files=True)\n",
        "train_ds = train_ds.map(img_process).cache().batch(64)\n",
        "test_ds = test_ds.map(img_process).cache().batch(64)\n"
      ],
      "metadata": {
        "id": "DCgzTXZF8Jja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Compile the VAE model, choosing an appropriate optimizer and learning rate,\n",
        "### the total_loss function as the model loss, and any appropriate metrics.\n",
        "\n",
        "vae = vae_model()\n",
        "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=recon_loss, metrics=['mse'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "oQ9PNmrk8iPO",
        "outputId": "3098bb11-29bb-402e-f31b-7746aceaadea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ca07f3d7a0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train the model using the train dataset for an appropriate number of epochs\n",
        "\n",
        "vae.fit(train_ds, epochs=10, validation_data=test_ds)\n",
        "\n",
        "### Store the losses and metrics in the history dictionary\n",
        "\n",
        "history = vae.history.history\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DVtYkya-8kpf",
        "outputId": "c5a891ea-519a-4783-ce70-c1a7f828d667"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ee96fc031f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Train the model using the train dataset for an appropriate number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### Store the losses and metrics in the history dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Plot the losses and metrics. Comment on the figures in your report, with\n",
        "### regard to how the training has proceeded.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history['loss'], label='loss')\n",
        "plt.plot(history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history['mse'], label='mse')\n",
        "plt.plot(history['val_mse'], label='val_mse')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_lzlRrQa8rL7",
        "outputId": "a3763374-0533-45d1-944c-2d14433aabdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3753ebeb3dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Using the test dataset, create a plot that shows the reconstruction quality\n",
        "### of the training model. Comment on the results in your report.\n",
        "\n",
        "def plot_recon(model, test_ds):\n",
        "    test_images = next(iter(test_ds))[0]\n",
        "    recon_images = model(test_images)\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "    for i in range(5):\n",
        "        axes[0, i].imshow(test_images[i])\n",
        "        axes[1, i].imshow(recon_images[i])\n",
        "    plt.show()\n",
        "    \n",
        "plot_recon(vae, test_ds)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "u_zSqvs88tkv",
        "outputId": "47cd948d-f94e-4cc6-9f84-b28bac6bab3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c97d6be7c735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_recon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Demonstrate the generative properties of the VAE by drawing randomly sampled\n",
        "### latent vectors from a unit Guassian and passing them to the train decoder.\n",
        "### Plot the results and comment on them in your report.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "z = np.random.normal(size=(5, 200))\n",
        "recon_images = decoder_model()(z)\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 4))\n",
        "\n",
        "for i in range(5):\n",
        "    axes[i].imshow(recon_images[i])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "vKi6qH-582d8",
        "outputId": "0bed0946-2bda-4685-9f65-5dfbd2c1bf94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ae994567641f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
          ]
        }
      ]
    }
  ]
}